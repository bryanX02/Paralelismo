{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d255bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset 'Maysee/tiny-imagenet'...\n",
      "Dataset cargado.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n",
      "\n",
      "Mostrando imagen de ejemplo (índice 2002 del conjunto 'train'):\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import ray\n",
    "import time \n",
    "# Carga del dataset\n",
    "print(\"Cargando dataset 'Maysee/tiny-imagenet'...\")\n",
    "tiny_imagenet = load_dataset('Maysee/tiny-imagenet')\n",
    "print(\"Dataset cargado.\")\n",
    "print(tiny_imagenet)\n",
    "\n",
    "# Accedermosa una imagen de ejemplo\n",
    "img_example = tiny_imagenet['train'][2002]['image']\n",
    "print(\"\\nMostrando imagen de ejemplo (índice 2002 del conjunto 'train'):\")\n",
    "img_example # En Jupyter, esto mostrará la imagen --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abb53f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el clasificador de imágenes 'image-classification'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e51894da7e9486f821f880cbc049c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354516e552da48f3910d2218c16d2794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador cargado.\n",
      "\n",
      "Clasificando la imagen de ejemplo:\n",
      "[{'label': 'African crocodile, Nile crocodile, Crocodylus niloticus', 'score': 0.7086568474769592}, {'label': 'American alligator, Alligator mississipiensis', 'score': 0.27417102456092834}, {'label': 'alligator lizard', 'score': 0.0010881631169468164}, {'label': 'frilled lizard, Chlamydosaurus kingi', 'score': 0.0005320230266079307}, {'label': 'rock python, rock snake, Python sebae', 'score': 0.0005290994886308908}]\n",
      "\n",
      "Mejor clasificación para la imagen de ejemplo: Clase='African crocodile, Nile crocodile, Crocodylus niloticus', Puntuación=0.7087\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo de clasificación de imágenes\n",
    "print(\"Cargando el clasificador de imágenes 'image-classification'...\")\n",
    "clf = pipeline(\"image-classification\", framework=\"pt\") # \"pt\" es para PyTorch\n",
    "print(\"Clasificador cargado.\")\n",
    "\n",
    "print(\"\\nClasificando la imagen de ejemplo:\")\n",
    "classification_result = clf(img_example)\n",
    "print(classification_result)\n",
    "\n",
    "# Función auxiliar para obtener la mejor clase y puntuación\n",
    "def get_best_class_and_score(classifier, pil_image):\n",
    "    \"\"\"\n",
    "    Clasifica una imagen y retorna la tupla (clase, puntuación) de la mejor predicción.\n",
    "    \"\"\"\n",
    "    predictions = classifier(pil_image)\n",
    "    if predictions: # Asegurarse de que hay predicciones\n",
    "        best_prediction = predictions[0] # La primera es la de mayor puntuación\n",
    "        return (best_prediction['label'], best_prediction['score'])\n",
    "    return (None, 0.0) # En caso de no haber predicciones\n",
    "\n",
    "# Probamos la función auxiliar\n",
    "best_class, best_score = get_best_class_and_score(clf, img_example)\n",
    "print(f\"\\nMejor clasificación para la imagen de ejemplo: Clase='{best_class}', Puntuación={best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5efead",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8adb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se procesarán 250 imágenes.\n"
     ]
    }
   ],
   "source": [
    "# Selección de las 250 imágenes a procesar\n",
    "image_indices = range(0, 10000, 40)\n",
    "images_to_classify_pil = [tiny_imagenet['train'][i]['image'] for i in image_indices]\n",
    "print(f\"Se procesarán {len(images_to_classify_pil)} imágenes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44eb2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión A: Recargando dataset y modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset y modelo recargados para Versión A.\n",
      "Iniciando clasificación secuencial...\n",
      "Clasificación secuencial completada. 250 imágenes procesadas.\n",
      "CPU times: user 5min 31s, sys: 12.8 s, total: 5min 43s\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Versión A: Secuencial\n",
    "\n",
    "print(\"Versión A: Recargando dataset y modelo...\")\n",
    "current_dataset_a = load_dataset('Maysee/tiny-imagenet', trust_remote_code=True) # Es buena práctica especificar trust_remote_code\n",
    "current_images_a = [current_dataset_a['train'][i]['image'] for i in range(0, 10000, 40)]\n",
    "current_clf_a = pipeline(\"image-classification\", framework=\"pt\")\n",
    "print(\"Dataset y modelo recargados para Versión A.\")\n",
    "\n",
    "results_a = []\n",
    "print(\"Iniciando clasificación secuencial...\")\n",
    "for img_pil in current_images_a:\n",
    "    best_class, best_score = get_best_class_and_score(current_clf_a, img_pil)\n",
    "    results_a.append((best_class, best_score))\n",
    "\n",
    "print(f\"Clasificación secuencial completada. {len(results_a)} imágenes procesadas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bfc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 18:00:28,205\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión B: Recargando dataset y modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset y modelo recargados para Versión B.\n",
      "Iniciando clasificación paralela con tareas de Ray...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(inference_task pid=7597)\u001b[0m 2025-05-21 18:00:43.190547: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(inference_task pid=7588)\u001b[0m 2025-05-21 18:00:43.276685: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=7597)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(inference_task pid=7597)\u001b[0m E0000 00:00:1747850443.440657    7597 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(inference_task pid=7588)\u001b[0m E0000 00:00:1747850443.448330    7588 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(inference_task pid=7589)\u001b[0m W0000 00:00:1747850443.576043    7589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=7589)\u001b[0m W0000 00:00:1747850443.576107    7589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=7589)\u001b[0m W0000 00:00:1747850443.576114    7589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=7589)\u001b[0m W0000 00:00:1747850443.576121    7589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=7597)\u001b[0m 2025-05-21 18:00:43.547341: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(inference_task pid=7597)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(inference_task pid=7585)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(inference_task pid=7585)\u001b[0m   from pandas.core import (\n",
      "\u001b[36m(inference_task pid=7599)\u001b[0m 2025-05-21 18:00:43.413434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 15x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(inference_task pid=7599)\u001b[0m 2025-05-21 18:00:43.483532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7585)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7585)\u001b[0m E0000 00:00:1747850443.601196    7585 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7599)\u001b[0m E0000 00:00:1747850443.597181    7599 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7598)\u001b[0m W0000 00:00:1747850443.600253    7598 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7598)\u001b[0m 2025-05-21 18:00:43.608418: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7598)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 2ae47157c3abb92407d05eaa49b99761e12c895301000000 Worker ID: ed640f09c85b162bb8624f89451c81c7d773e32ac854b477dbd4f2cc Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 43617 Worker PID: 7597 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: e80013b9d05f12cd4045b4c86eda3de20fe6898201000000 Worker ID: 0eb8abb8c90e9872bce235b65b03f7c04050bb9c9f0ca27f996e0594 Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 37137 Worker PID: 7585 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:01:49,311 E 7508 7508] (raylet) node_manager.cc:3287: 4 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(inference_task pid=7598)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=7598)\u001b[0m   from pandas.core import (\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 6e78c6086208d3d9c9bfc5ee6c8b168716c4653801000000 Worker ID: b9e5a1372ae8eaf97cd3379108261a2e8c7263fe2132e5ae95bf482f Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 34169 Worker PID: 7589 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 68b9375466619fa436c569e16b5ebb30fc352b2401000000 Worker ID: dd5c42a61666fb45421f3078a248ec51f0ea517f9ba292e8f129c5c5 Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 38171 Worker PID: 7592 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:02:00,374 E 7508 7508] (raylet) worker_pool.cc:586: Some workers of the worker process(8640) have not registered within the timeout. The process is still alive, probably it's hanging during start.\n",
      "\u001b[36m(inference_task pid=8657)\u001b[0m 2025-05-21 18:02:22.188489: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m 2025-05-21 18:02:22.694438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m E0000 00:00:1747850542.876761    8655 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m E0000 00:00:1747850542.968647    8655 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m W0000 00:00:1747850543.468343    8655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m W0000 00:00:1747850543.468397    8655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m W0000 00:00:1747850543.468406    8655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m W0000 00:00:1747850543.468413    8655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m 2025-05-21 18:02:23.523550: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(inference_task pid=8655)\u001b[0m   from pandas.core import (\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m 2025-05-21 18:02:25.713085: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m 2025-05-21 18:02:25.749315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m E0000 00:00:1747850545.820071   10162 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m E0000 00:00:1747850545.835092   10162 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m W0000 00:00:1747850545.873872   10162 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m 2025-05-21 18:02:25.883898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 4f4172517cd43da315de153d915a5d784c795b7b01000000 Worker ID: 82138e7b531625639990981c1d89944728f35f4e26a43c6eb0244f4b Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 41835 Worker PID: 10162 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 525e615894d75050abb0739f204dce4baffdf9c801000000 Worker ID: e9e450d5e6c2e23835ab65825c5d9877d40b8cae1a293d2cfa07bfa5 Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 42679 Worker PID: 9034 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker connection closed unexpectedly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:02:57,446 E 7508 7508] (raylet) node_manager.cc:3287: 9 Workers (tasks / actors) killed due to memory pressure (OOM), 1 Workers crashed due to other reasons at node (ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10162)\u001b[0m   from pandas.core import (\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m 2025-05-21 18:03:05.354222: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m 2025-05-21 18:03:05.835160: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m E0000 00:00:1747850586.023423   10501 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m E0000 00:00:1747850586.076237   10501 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m W0000 00:00:1747850586.631990   10501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m W0000 00:00:1747850586.632090   10501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m W0000 00:00:1747850586.632101   10501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m W0000 00:00:1747850586.632109   10501 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m 2025-05-21 18:03:06.696559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m 2025-05-21 18:03:15.657574: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m 2025-05-21 18:03:05.835148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m E0000 00:00:1747850586.023408   10778 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m E0000 00:00:1747850586.076296   10778 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m W0000 00:00:1747850586.632134   10778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m 2025-05-21 18:03:06.696558: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(inference_task pid=10778)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m 2025-05-21 18:03:15.773488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m E0000 00:00:1747850595.825353   11001 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m E0000 00:00:1747850595.841767   11001 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m 2025-05-21 18:03:15.897911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(inference_task pid=10501)\u001b[0m   from pandas.core import (\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m 2025-05-21 18:03:15.657324: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10999)\u001b[0m W0000 00:00:1747850595.917017   10999 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11392)\u001b[0m 2025-05-21 18:03:15.774468: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m E0000 00:00:1747850595.839254   11398 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m E0000 00:00:1747850595.857582   11398 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10999)\u001b[0m 2025-05-21 18:03:15.929361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=10999)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11001)\u001b[0m   from pandas.core import (\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 0c0178511653498e27e91c16dc5c7e8b174780f501000000 Worker ID: d510cc4416940631022531f7da40a3441fce04f5833af9e929ba8758 Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 34951 Worker PID: 8642 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 0992e81e2e196ad37941fa1e0a14e317c0a27b4a01000000 Worker ID: 3aeaf2fa9abe814bdad486124d01618efa5b317fb1342790ee906ac4 Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 40759 Worker PID: 8668 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(inference_task pid=11880)\u001b[0m 2025-05-21 18:03:43.437687: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=11398)\u001b[0m   from pandas.core import (\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 2b544e8b20e06aa0217bc3194bd7a08c2474bb7d01000000 Worker ID: 04ef7618c3a7c692087a14ecccc1083b7e8884627c54a51786547b5e Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 41505 Worker PID: 8669 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:04:01,811 E 7508 7508] (raylet) node_manager.cc:3287: 9 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m 2025-05-21 18:04:03.127405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m E0000 00:00:1747850643.751929   11880 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m E0000 00:00:1747850643.856592   11880 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m W0000 00:00:1747850644.440423   11880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m W0000 00:00:1747850644.440509   11880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m W0000 00:00:1747850644.440518   11880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m W0000 00:00:1747850644.440525   11880 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m 2025-05-21 18:04:04.493124: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(inference_task pid=12249)\u001b[0m 2025-05-21 18:04:06.329880: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(inference_task pid=12249)\u001b[0m 2025-05-21 18:04:06.488482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m 2025-05-21 18:04:08.512084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(inference_task pid=11880)\u001b[0m   from pandas.core import (\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m E0000 00:00:1747850648.544041   12569 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m E0000 00:00:1747850648.552158   12569 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m W0000 00:00:1747850648.574264   12569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m 2025-05-21 18:04:08.580770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12569)\u001b[0m 2025-05-21 18:04:08.485102: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 6590bf94ccd4b4e5ed3ce01448ad159bb062ed5b01000000 Worker ID: d398e36cd45faf3a7659bd38b700dbd27e8a9e675a96816fec5c03d9 Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 41765 Worker PID: 12572 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(inference_task pid=12919)\u001b[0m 2025-05-21 18:04:12.347271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12905)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12905)\u001b[0m   from pandas.core import (\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12906)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12906)\u001b[0m E0000 00:00:1747850652.424016   12906 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12906)\u001b[0m E0000 00:00:1747850652.438751   12906 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12919)\u001b[0m W0000 00:00:1747850652.446203   12919 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12919)\u001b[0m 2025-05-21 18:04:12.454832: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12919)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(inference_task pid=12919)\u001b[0m 2025-05-21 18:04:12.315232: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 4816786f48f195a1963693ef20aeb1a700c709e801000000 Worker ID: 138bae7e3160fa293f35e4bdeeabd976d31aac54b8a1a86734d4a0eb Node ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a Worker IP address: 172.17.0.2 Worker port: 33171 Worker PID: 12905 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "Clasificación con tareas de Ray completada. 250 imágenes procesadas.\n",
      "CPU times: user 3.23 s, sys: 54.4 s, total: 57.6 s\n",
      "Wall time: 4min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:05:27,896 E 7508 7508] (raylet) node_manager.cc:3287: 4 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(pid=13803)\u001b[0m 2025-05-21 18:05:43.585124: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=13803)\u001b[0m 2025-05-21 18:05:44.044502: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=13803)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=13803)\u001b[0m E0000 00:00:1747850744.265895   13803 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=13814)\u001b[0m E0000 00:00:1747850744.319696   13814 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=13803)\u001b[0m W0000 00:00:1747850744.710080   13803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=13803)\u001b[0m W0000 00:00:1747850744.710140   13803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=13803)\u001b[0m W0000 00:00:1747850744.710147   13803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=13803)\u001b[0m W0000 00:00:1747850744.710153   13803 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=13803)\u001b[0m 2025-05-21 18:05:44.755808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=13803)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=13803)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(pid=13803)\u001b[0m   from pandas.core import (\n",
      "\u001b[36m(pid=13812)\u001b[0m 2025-05-21 18:05:43.585138: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13812)\u001b[0m 2025-05-21 18:05:44.044454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13812)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13812)\u001b[0m E0000 00:00:1747850744.265745   13812 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13802)\u001b[0m E0000 00:00:1747850744.319463   13802 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13812)\u001b[0m W0000 00:00:1747850744.710165   13812 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13812)\u001b[0m 2025-05-21 18:05:44.757607: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13812)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "\u001b[36m(pid=13802)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=13802)\u001b[0m   from pandas.core import (\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m Actor InferenceEngine inicializando. load_images=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=13808)\u001b[0m Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "\u001b[36m(InferenceEngine pid=13813)\u001b[0m Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=13805)\u001b[0m Actor cargando dataset 'Maysee/tiny-imagenet'...\n",
      "\u001b[36m(InferenceEngine pid=13808)\u001b[0m Actor: dataset cargado.\n",
      "\u001b[36m(InferenceEngine pid=13808)\u001b[0m Actor InferenceEngine inicializado.\n",
      "\u001b[36m(InferenceEngine pid=13812)\u001b[0m Actor InferenceEngine inicializando. load_images=True\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m Actor cargando dataset 'Maysee/tiny-imagenet'...\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=13812)\u001b[0m No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13812)\u001b[0m Using a pipeline without specifying a model name and revision in production is not recommended.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13806)\u001b[0m Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m Device set to use cpu\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m Actor: dataset cargado.\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13803)\u001b[0m Actor InferenceEngine inicializado.\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=13806)\u001b[0m Actor cargando dataset 'Maysee/tiny-imagenet'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:06:27,902 E 7508 7508] (raylet) node_manager.cc:3287: 10 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(InferenceEngine pid=13806)\u001b[0m Device set to use cpu\n",
      "\u001b[36m(pid=15045)\u001b[0m 2025-05-21 18:07:47.926011: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=15045)\u001b[0m 2025-05-21 18:07:48.337522: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=15045)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=15045)\u001b[0m E0000 00:00:1747850868.508820   15045 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=15049)\u001b[0m E0000 00:00:1747850868.554824   15049 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=15045)\u001b[0m W0000 00:00:1747850868.893394   15045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=15045)\u001b[0m W0000 00:00:1747850868.893496   15045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=15045)\u001b[0m W0000 00:00:1747850868.893502   15045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=15045)\u001b[0m W0000 00:00:1747850868.893507   15045 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=15045)\u001b[0m 2025-05-21 18:07:48.931929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=15045)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=15045)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(pid=15045)\u001b[0m   from pandas.core import (\n",
      "\u001b[36m(pid=15052)\u001b[0m 2025-05-21 18:07:47.925760: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m 2025-05-21 18:07:48.337527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m E0000 00:00:1747850868.509042   15052 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15053)\u001b[0m E0000 00:00:1747850868.554793   15053 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m W0000 00:00:1747850868.893622   15052 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m 2025-05-21 18:07:48.931854: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=15053)\u001b[0m Actor InferenceEngine inicializando. load_images=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=15045)\u001b[0m No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "\u001b[36m(InferenceEngine pid=15045)\u001b[0m Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "\u001b[36m(pid=15052)\u001b[0m /usr/local/lib/python3.11/dist-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=15052)\u001b[0m   from pandas.core import (\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=15045)\u001b[0m Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "\u001b[36m(InferenceEngine pid=15045)\u001b[0m Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InferenceEngine pid=15053)\u001b[0m Actor InferenceEngine inicializado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-05-21 18:08:27,907 E 7508 7508] (raylet) node_manager.cc:3287: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5245c351d8875657ab602cd0b6baee5a0531dc033e842ef1b358919a, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(InferenceEngine pid=15052)\u001b[0m No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=15052)\u001b[0m Using a pipeline without specifying a model name and revision in production is not recommended.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=15052)\u001b[0m Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(InferenceEngine pid=15043)\u001b[0m Device set to use cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Versión B: Paralela con Tareas Remotas de Ray\n",
    "\n",
    "# Recargamos el dataset y el modelo\n",
    "print(\"Versión B: Recargando dataset y modelo...\")\n",
    "current_dataset_b = load_dataset('Maysee/tiny-imagenet', trust_remote_code=True)\n",
    "current_images_b_pil = [current_dataset_b['train'][i]['image'] for i in range(0, 10000, 40)]\n",
    "current_clf_b = pipeline(\"image-classification\", framework=\"pt\")\n",
    "print(\"Dataset y modelo recargados para Versión B.\")\n",
    "\n",
    "\n",
    "# Definmos la tarea remota de Ray\n",
    "@ray.remote\n",
    "def inference_task(classifier, image_pil):\n",
    "    # Esta función se ejecuta como una tarea remota de Ray\n",
    "    return get_best_class_and_score(classifier, image_pil)\n",
    "\n",
    "# Almacenar el clasificador en el object store de Ray\n",
    "clf_ref_b = ray.put(current_clf_b)\n",
    "\n",
    "print(\"Iniciando clasificación paralela con tareas de Ray...\")\n",
    "# Lanzamos las tareas remotas\n",
    "# Pasamos la referencia al clasificador y cada imagen individualmente\n",
    "result_refs_b = [inference_task.remote(clf_ref_b, img_pil) for img_pil in current_images_b_pil]\n",
    "\n",
    "# resultados\n",
    "results_b = ray.get(result_refs_b)\n",
    "\n",
    "print(f\"Clasificación con tareas de Ray completada. {len(results_b)} imágenes procesadas.\")\n",
    "\n",
    "del clf_ref_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab27ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class InferenceEngine:\n",
    "    def __init__(self, load_images=True):\n",
    "        print(f\"Actor InferenceEngine inicializando. load_images={load_images}\")\n",
    "        # Cada actor carga su propia instancia del clasificador\n",
    "        self.classifier = pipeline(\"image-classification\")\n",
    "        self.dataset_train = None\n",
    "        if load_images:\n",
    "            # Cada actor carga el dataset si es necesario\n",
    "            print(\"Actor cargando dataset 'Maysee/tiny-imagenet'...\")\n",
    "            self.dataset_train = load_dataset('Maysee/tiny-imagenet', trust_remote_code=True)['train']\n",
    "            print(\"Actor: dataset cargado.\")\n",
    "        else:\n",
    "            self.dataset_train = None\n",
    "        print(\"Actor InferenceEngine inicializado.\")\n",
    "\n",
    "    def classify_image_by_index(self, image_index):\n",
    "        \"\"\"\n",
    "        Clasifica una imagen del dataset interno del actor, especificada por su índice.\n",
    "        \"\"\"\n",
    "        # print(f\"Actor clasificando imagen por índice: {image_index}\")\n",
    "        if self.dataset_train is None:\n",
    "            return (\"Error: El dataset no está cargado en este actor o índice fuera de rango\", -1.0)\n",
    "        \n",
    "        try:\n",
    "            # Extraer la imagen PIL del dataset del actor\n",
    "            image_pil = self.dataset_train[image_index]['image']\n",
    "            return get_best_class_and_score(self.classifier, image_pil)\n",
    "        except IndexError:\n",
    "            return (f\"Error: Índice {image_index} fuera de rango para el dataset del actor\", -1.0)\n",
    "        except Exception as e:\n",
    "            return (f\"Error al procesar imagen por índice {image_index}: {str(e)}\", -1.0)\n",
    "\n",
    "    def classify_image_object(self, image_pil_object):\n",
    "        \"\"\"\n",
    "        Clasifica un objeto de imagen PIL pasado como parámetro.\n",
    "        \"\"\"\n",
    "        # print(\"Actor clasificando objeto de imagen PIL...\")\n",
    "        if image_pil_object is None:\n",
    "            return (\"Error: Objeto de imagen PIL es None\", -1.0)\n",
    "        return get_best_class_and_score(self.classifier, image_pil_object)\n",
    "\n",
    "    def get_classifier_pid(self): # Método de ayuda para depuración (opcional)\n",
    "        import os\n",
    "        return os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c26c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión C1: Creando 16 actores. Cada actor cargará el dataset.\n",
      "16 actores creados para Versión C1.\n",
      "Iniciando clasificación con actores (C1)...\n",
      "Clasificación con actores (C1) completada. 250 imágenes procesadas.\n",
      "Destruyendo actores de Versión C1...\n",
      "Actores de Versión C1 destruidos.\n",
      "CPU times: user 1.07 s, sys: 7.26 s, total: 8.33 s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Versión C1: Actores con dataset en memoria en cada actor\n",
    "\n",
    "# Número de actores = número de CPUs disponibles (o un número fijo si prefieres)\n",
    "num_actors = ray.available_resources().get(\"CPU\", 1) # Obtiene los CPUs lógicos\n",
    "num_actors = int(num_actors) if num_actors else 2 # Usar al menos 2 si no se detectan CPUs\n",
    "print(f\"Versión C1: Creando {num_actors} actores. Cada actor cargará el dataset.\")\n",
    "\n",
    "# Creamos los actores, cada uno cargará el dataset\n",
    "actors_c1 = [InferenceEngine.remote(load_images=True) for _ in range(num_actors)]\n",
    "print(f\"{len(actors_c1)} actores creados para Versión C1.\")\n",
    "\n",
    "image_indices_c1 = list(range(0, 10000, 40)) \n",
    "\n",
    "results_c1 = []\n",
    "result_refs_c1 = []\n",
    "print(\"Iniciando clasificación con actores (C1)...\")\n",
    "\n",
    "# Asignamos trabajo de forma rotatoria (round-robin) a los actores\n",
    "for i, image_idx in enumerate(image_indices_c1):\n",
    "    actor_index = i % num_actors\n",
    "    result_refs_c1.append(actors_c1[actor_index].classify_image_by_index.remote(image_idx))\n",
    "\n",
    "results_c1 = ray.get(result_refs_c1)\n",
    "\n",
    "print(f\"Clasificación con actores (C1) completada. {len(results_c1)} imágenes procesadas.\")\n",
    "\n",
    "# Destruimos los actores para liberar recursos\n",
    "print(\"Destruyendo actores de Versión C1...\")\n",
    "for actor in actors_c1:\n",
    "    ray.kill(actor)\n",
    "print(\"Actores de Versión C1 destruidos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed3c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión C2: Recargando dataset en el driver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/main/README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/main/README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/main/README.md\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/main/README.md\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/main/README.md\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/main/README.md\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/5a77092c28e51558c5586e9c5eb71a7e17a5e43f/tiny-imagenet.py\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/5a77092c28e51558c5586e9c5eb71a7e17a5e43f/tiny-imagenet.py\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/5a77092c28e51558c5586e9c5eb71a7e17a5e43f/tiny-imagenet.py\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/Maysee/tiny-imagenet/resolve/5a77092c28e51558c5586e9c5eb71a7e17a5e43f/tiny-imagenet.py\n",
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado en el driver para Versión C2.\n",
      "Versión C2: Creando 16 actores. Los actores NO cargarán el dataset.\n",
      "16 actores creados para Versión C2.\n",
      "Iniciando clasificación con actores (C2)...\n",
      "Clasificación con actores (C2) completada. 250 imágenes procesadas.\n",
      "Destruyendo actores de Versión C2...\n",
      "Actores de Versión C2 destruidos.\n",
      "CPU times: user 1 s, sys: 442 ms, total: 1.44 s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Versión C2: Actores sin dataset en memoria (dataset en driver)\n",
    "\n",
    "# Recargamos el dataset en el driver\n",
    "print(\"Versión C2: Recargando dataset en el driver...\")\n",
    "current_dataset_c2 = load_dataset('Maysee/tiny-imagenet', trust_remote_code=True)\n",
    "images_to_classify_pil_c2 = [current_dataset_c2['train'][i]['image'] for i in range(0, 10000, 40)]\n",
    "print(\"Dataset cargado en el driver para Versión C2.\")\n",
    "\n",
    "num_actors_c2 = int(ray.available_resources().get(\"CPU\", 1) or 2)\n",
    "print(f\"Versión C2: Creando {num_actors_c2} actores. Los actores NO cargarán el dataset.\")\n",
    "\n",
    "actors_c2 = [InferenceEngine.remote(load_images=False) for _ in range(num_actors_c2)]\n",
    "print(f\"{len(actors_c2)} actores creados para Versión C2.\")\n",
    "\n",
    "results_c2 = []\n",
    "result_refs_c2 = []\n",
    "print(\"Iniciando clasificación con actores (C2)...\")\n",
    "\n",
    "# Asignamos trabajo de forma rotatoria\n",
    "for i, image_pil_obj in enumerate(images_to_classify_pil_c2):\n",
    "    actor_index = i % num_actors_c2\n",
    "    result_refs_c2.append(actors_c2[actor_index].classify_image_object.remote(image_pil_obj))\n",
    "\n",
    "results_c2 = ray.get(result_refs_c2)\n",
    "\n",
    "print(f\"Clasificación con actores (C2) completada. {len(results_c2)} imágenes procesadas.\")\n",
    "# print(\"\\nPrimeros 5 resultados de la Versión C2:\")\n",
    "# for i in range(min(5, len(results_c2))):\n",
    "# print(f\"  {results_c2[i]}\")\n",
    "\n",
    "# Y destruimos los actores\n",
    "print(\"Destruyendo actores de Versión C2...\")\n",
    "for actor in actors_c2:\n",
    "    ray.kill(actor)\n",
    "print(\"Actores de Versión C2 destruidos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42144ac1",
   "metadata": {},
   "source": [
    "## CONCLUISION\n",
    "\n",
    "En este entorno con limitaciones de memoria evidentes (que causan OOMs), la Versión A (secuencial) resultó ser la más rápida (46.5 s) porque evitó la sobrecarga y los fallos de un sistema distribuido bajo presión.\n",
    "La Versión B (tareas) fue la menos eficiente debido a la alta sobrecarga por tarea y los masivos errores OOM.\n",
    "Las Versiones C1 y C2 (actores) ofrecieron un rendimiento mucho mejor que B y similar entre sí (alrededor de 1m 41s). Los actores son más eficientes que las tareas para este tipo de trabajo porque el modelo (pipeline) se carga una sola vez por actor, en lugar de potencialmente en cada tarea. \n",
    "Entre C1 y C2, C2 (dataset en driver) parece ser un diseño más robusto para la memoria en este escenario, ya que evitó los OOM en los actores (aunque C1 solo reportó uno). Si el dataset fuera mucho más grande o el número de actores mayor, la ventaja de C2 en términos de memoria sería más pronunciada. La pequeña diferencia de tiempo entre C1 y C2 podría estar influenciada por el OOM en C1 y los retrasos de descarga en C2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7460f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
